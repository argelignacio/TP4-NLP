{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\igna-\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importacion general de librerias y de visualizacion (matplotlib y seaborn)\n",
    "import pandas as pd\n",
    "import scipy \n",
    "import numpy as np\n",
    "import random as rd\n",
    "import nltk\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "nltk.download('stopwords')\n",
    "\n",
    "plt.style.use('default') # haciendo los graficos un poco mas bonitos en matplotlib\n",
    "#plt.rcParams['figure.figsize'] = (20, 10)\n",
    "\n",
    "sns.set(style=\"whitegrid\") # seteando tipo de grid en seaborn\n",
    "\n",
    "pd.options.display.float_format = '{:20,.2f}'.format # suprimimos la notacion cientifica en los outputs\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo y spliteo el set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('train_EN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tweets.iloc[:,1:3]\n",
    "train.dropna(inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not ‚Äúforced‚Äù to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>The population spike in Chicago in 9 months is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>You'd think in the second to last English clas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>I‚Äôm finally surfacing after a holiday to Scotl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>Couldn't be prouder today. Well done to every ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>Overheard as my 13 year old games with a frien...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3467 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  sarcastic\n",
       "0     The only thing I got from college is a caffein...          1\n",
       "1     I love it when professors draw a big question ...          1\n",
       "2     Remember the hundred emails from companies whe...          1\n",
       "3     Today my pop-pop told me I was not ‚Äúforced‚Äù to...          1\n",
       "4     @VolphanCarol @littlewhitty @mysticalmanatee I...          1\n",
       "...                                                 ...        ...\n",
       "3463  The population spike in Chicago in 9 months is...          0\n",
       "3464  You'd think in the second to last English clas...          0\n",
       "3465  I‚Äôm finally surfacing after a holiday to Scotl...          0\n",
       "3466  Couldn't be prouder today. Well done to every ...          0\n",
       "3467  Overheard as my 13 year old games with a frien...          0\n",
       "\n",
       "[3467 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet'] = train['tweet'].str.lower()\n",
    "train['tweet'] = train['tweet'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizo los textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3467/3467 [00:00<00:00, 4197.35it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = []\n",
    "for text in tqdm(train['tweet']):\n",
    "    tokenized_texts.append(nltk.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo la matriz de embbedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " w2v_model.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix = np.concatenate([np.zeros((1,300)), \n",
    "                             np.random.normal(size=(1,300)),\n",
    "                             w2v_model.vectors[:500000]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train['tweet'], train['sarcastic'], test_size=0.2, train_size=0.8, random_state=1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.dropna()\n",
    "y_test = y_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = int(np.percentile([len(t) for t in tokenized_texts], 95))\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_toks(tokenized_text):\n",
    "    tokenized_text =tokenized_text.copy()\n",
    "    if len(tokenized_text) > MAX_LEN:\n",
    "        tokenized_text = tokenized_text[:MAX_LEN]\n",
    "    for i in range(len(tokenized_text)):\n",
    "        if tokenized_text[i] in w2v_model and w2v_model.key_to_index[tokenized_text[i]] < 500000:\n",
    "            tokenized_text[i] = w2v_model.key_to_index[tokenized_text[i]]+2\n",
    "        else:\n",
    "            tokenized_text[i] = 1\n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500002, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3467/3467 [00:00<00:00, 10829.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(tokenized_texts)), total=len(tokenized_texts)):\n",
    "    tokenized_texts[i] = preprocess_toks(tokenized_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "tokenized_texts = pad_sequences(\n",
    "    tokenized_texts, maxlen=MAX_LEN, dtype='int32', padding='post',\n",
    "    truncating='post', value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, GRU, Embedding, LSTM\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indexes = Input((50,), dtype='int32')\n",
    "\n",
    "word_emb = Embedding(500002, 300, weights=[emb_matrix], \n",
    "                     trainable=False, mask_zero=True)\n",
    "\n",
    "emb_sequence = word_emb(word_indexes) # (22, 300)\n",
    "rnn1 = GRU(50, activation='tanh')(emb_sequence) # (1,50)\n",
    "dense1 = Dense(50, activation='tanh')(rnn1)\n",
    "dense2 = Dense(50, activation='tanh')(dense1)\n",
    "dense3 = Dense(50, activation='tanh')(dense2)\n",
    "\n",
    "out = Dense(1, activation=None)(dense3)\n",
    "model = Model(inputs=word_indexes, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=opt, loss=\"mse\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14/14 [==============================] - 8s 114ms/step - loss: 0.2437 - mae: 0.3995\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.1970 - mae: 0.3664\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.1878 - mae: 0.3688\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.1841 - mae: 0.3659\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.1822 - mae: 0.3666\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.1812 - mae: 0.3634\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 0.1800 - mae: 0.3579\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.1804 - mae: 0.3681\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.1753 - mae: 0.3526\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.1727 - mae: 0.3521\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.1746 - mae: 0.3452\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.1701 - mae: 0.3514\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.1671 - mae: 0.3402\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.1634 - mae: 0.3372\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.1626 - mae: 0.3347\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.1598 - mae: 0.3360\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.1549 - mae: 0.3276\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.1529 - mae: 0.3192\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.1486 - mae: 0.3184\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.1527 - mae: 0.3186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24892703a60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tokenized_texts, train['sarcastic'].values, epochs=20, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298     damn, imagine being vaxxed and then getting a ...\n",
       "1691    that second vaccine dose is no joke is it üòµ be...\n",
       "1407    my essay was so bad that my prof is giving me ...\n",
       "1888    @iamgryphoneer i don't like to rag on people's...\n",
       "1047    my stray boy playing‚Ä¶ he is looking well but s...\n",
       "                              ...                        \n",
       "2275    damn instagram engagement is slow üò≠ 2 likes in...\n",
       "1006    i gotta get out of this city. i made $18 doord...\n",
       "1563    my grandpa has covid so i made a lil care pack...\n",
       "2630    the last football game i went too. 1 year toda...\n",
       "1615         words cannot express how much i hate glitter\n",
       "Name: tweet, Length: 694, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 694/694 [00:00<00:00, 3652.78it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts_test = []\n",
    "for texto in tqdm(X_test):\n",
    "    tokenized_texts_test.append(nltk.word_tokenize(texto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 694/694 [00:00<00:00, 3691.68it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(tokenized_texts_test)), total=len(tokenized_texts_test)):\n",
    "    tokenized_texts_test[i] = preprocess_toks(tokenized_texts_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts_test = pad_sequences(\n",
    "    tokenized_texts_test, maxlen=MAX_LEN, dtype='int32', padding='post',\n",
    "    truncating='post', value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(tokenized_texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8208948296667595"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_indexes = Input((50,), dtype='int32')\n",
    "\n",
    "word_emb = Embedding(500002, 300, weights=[emb_matrix], \n",
    "                     trainable=False, mask_zero=True)\n",
    "\n",
    "emb_sequence = word_emb(word_indexes) # (22, 300)\n",
    "rnn1 = LSTM(50, activation='tanh')(emb_sequence) # (1,50)\n",
    "dense1 = Dense(50, activation='tanh')(rnn1)\n",
    "dense2 = Dense(50, activation='tanh')(dense1)\n",
    "dense3 = Dense(50, activation='tanh')(dense2)\n",
    "\n",
    "out = Dense(1, activation=None)(dense3)\n",
    "model = Model(inputs=word_indexes, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "auc = keras.metrics.AUC(\n",
    "    num_thresholds=200, curve='ROC',\n",
    "    summation_method='interpolation', name=None, dtype=None,\n",
    "    thresholds=None, multi_label=False, num_labels=None, label_weights=None,\n",
    "    from_logits=False\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt, loss=\"mse\", metrics=[auc])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (model_1/dense_7/BiasAdd:0) = ] [[0.346226][-0.0469980575][0.429081261]...] [y (Cast_3/x:0) = ] [0]\n\t [[node assert_greater_equal/Assert/AssertGuard/Assert\n (defined at C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\utils\\metrics_utils.py:608)\n]] [Op:__inference_train_function_44512]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node assert_greater_equal/Assert/AssertGuard/Assert:\nIn[0] assert_greater_equal/Assert/AssertGuard/Assert/assert_greater_equal/All:\t\nIn[1] assert_greater_equal/Assert/AssertGuard/Assert/data_0:\t\nIn[2] assert_greater_equal/Assert/AssertGuard/Assert/data_1:\t\nIn[3] assert_greater_equal/Assert/AssertGuard/Assert/data_2:\t\nIn[4] assert_greater_equal/Assert/AssertGuard/Assert/model_1/dense_7/BiasAdd:\t\nIn[5] assert_greater_equal/Assert/AssertGuard/Assert/data_4:\t\nIn[6] assert_greater_equal/Assert/AssertGuard/Assert/Cast_3/x:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n>>>     self.run()\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-63-ad48a4671b9b>\", line 1, in <module>\n>>>     model.fit(tokenized_texts, train['sarcastic'].values, validation_split=0.1, epochs=20, batch_size=256)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 817, in train_step\n>>>     self.compiled_metrics.update_state(y, y_pred, sample_weight)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 460, in update_state\n>>>     metric_obj.update_state(y_t, y_p, sample_weight=mask)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 73, in decorated\n>>>     update_op = update_state_fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\metrics.py\", line 177, in update_state_fn\n>>>     return ag_update_state(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\metrics.py\", line 2343, in update_state\n>>>     return metrics_utils.update_confusion_matrix_variables(\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 608, in update_confusion_matrix_variables\n>>>     tf.compat.v1.assert_greater_equal(\n>>> \n\nFunction call stack:\ntrain_function -> assert_greater_equal_Assert_AssertGuard_false_44379\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-ad48a4671b9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenized_texts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sarcastic'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (model_1/dense_7/BiasAdd:0) = ] [[0.346226][-0.0469980575][0.429081261]...] [y (Cast_3/x:0) = ] [0]\n\t [[node assert_greater_equal/Assert/AssertGuard/Assert\n (defined at C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\utils\\metrics_utils.py:608)\n]] [Op:__inference_train_function_44512]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node assert_greater_equal/Assert/AssertGuard/Assert:\nIn[0] assert_greater_equal/Assert/AssertGuard/Assert/assert_greater_equal/All:\t\nIn[1] assert_greater_equal/Assert/AssertGuard/Assert/data_0:\t\nIn[2] assert_greater_equal/Assert/AssertGuard/Assert/data_1:\t\nIn[3] assert_greater_equal/Assert/AssertGuard/Assert/data_2:\t\nIn[4] assert_greater_equal/Assert/AssertGuard/Assert/model_1/dense_7/BiasAdd:\t\nIn[5] assert_greater_equal/Assert/AssertGuard/Assert/data_4:\t\nIn[6] assert_greater_equal/Assert/AssertGuard/Assert/Cast_3/x:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n>>>     self.run()\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-63-ad48a4671b9b>\", line 1, in <module>\n>>>     model.fit(tokenized_texts, train['sarcastic'].values, validation_split=0.1, epochs=20, batch_size=256)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 817, in train_step\n>>>     self.compiled_metrics.update_state(y, y_pred, sample_weight)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 460, in update_state\n>>>     metric_obj.update_state(y_t, y_p, sample_weight=mask)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 73, in decorated\n>>>     update_op = update_state_fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\metrics.py\", line 177, in update_state_fn\n>>>     return ag_update_state(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\metrics.py\", line 2343, in update_state\n>>>     return metrics_utils.update_confusion_matrix_variables(\n>>> \n>>>   File \"C:\\Users\\igna-\\anaconda3\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 608, in update_confusion_matrix_variables\n>>>     tf.compat.v1.assert_greater_equal(\n>>> \n\nFunction call stack:\ntrain_function -> assert_greater_equal_Assert_AssertGuard_false_44379\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(tokenized_texts, train['sarcastic'].values, validation_split=0.1, callbacks=[callback], epochs=20, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(tokenized_texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "roc_auc_score(y_test, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
