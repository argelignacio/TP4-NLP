{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\igna-\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importacion general de librerias y de visualizacion (matplotlib y seaborn)\n",
    "import pandas as pd\n",
    "import scipy \n",
    "import numpy as np\n",
    "import random as rd\n",
    "import nltk\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "nltk.download('stopwords')\n",
    "\n",
    "plt.style.use('default') # haciendo los graficos un poco mas bonitos en matplotlib\n",
    "#plt.rcParams['figure.figsize'] = (20, 10)\n",
    "\n",
    "sns.set(style=\"whitegrid\") # seteando tipo de grid en seaborn\n",
    "\n",
    "pd.options.display.float_format = '{:20,.2f}'.format # suprimimos la notacion cientifica en los outputs\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo y spliteo el set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('train_EN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tweets.iloc[:,1:3]\n",
    "train.dropna(inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>The population spike in Chicago in 9 months is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>You'd think in the second to last English clas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>I’m finally surfacing after a holiday to Scotl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>Couldn't be prouder today. Well done to every ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>Overheard as my 13 year old games with a frien...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3467 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  sarcastic\n",
       "0     The only thing I got from college is a caffein...          1\n",
       "1     I love it when professors draw a big question ...          1\n",
       "2     Remember the hundred emails from companies whe...          1\n",
       "3     Today my pop-pop told me I was not “forced” to...          1\n",
       "4     @VolphanCarol @littlewhitty @mysticalmanatee I...          1\n",
       "...                                                 ...        ...\n",
       "3463  The population spike in Chicago in 9 months is...          0\n",
       "3464  You'd think in the second to last English clas...          0\n",
       "3465  I’m finally surfacing after a holiday to Scotl...          0\n",
       "3466  Couldn't be prouder today. Well done to every ...          0\n",
       "3467  Overheard as my 13 year old games with a frien...          0\n",
       "\n",
       "[3467 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet'] = train['tweet'].str.lower()\n",
    "train['tweet'] = train['tweet'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizo los textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3467/3467 [00:00<00:00, 4197.35it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = []\n",
    "for text in tqdm(train['tweet']):\n",
    "    tokenized_texts.append(nltk.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo la matriz de embbedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " w2v_model.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix = np.concatenate([np.zeros((1,300)), \n",
    "                             np.random.normal(size=(1,300)),\n",
    "                             w2v_model.vectors[:500000]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train['tweet'], train['sarcastic'], test_size=0.2, train_size=0.8, random_state=1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.dropna()\n",
    "y_test = y_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298     1\n",
       "1691    0\n",
       "1407    0\n",
       "1888    0\n",
       "1047    0\n",
       "       ..\n",
       "2275    0\n",
       "1006    0\n",
       "1563    0\n",
       "2630    0\n",
       "1615    0\n",
       "Name: sarcastic, Length: 694, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = int(np.percentile([len(t) for t in tokenized_texts], 95))\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_toks(tokenized_text):\n",
    "    tokenized_text =tokenized_text.copy()\n",
    "    if len(tokenized_text) > MAX_LEN:\n",
    "        tokenized_text = tokenized_text[:MAX_LEN]\n",
    "    for i in range(len(tokenized_text)):\n",
    "        if tokenized_text[i] in w2v_model and w2v_model.key_to_index[tokenized_text[i]] < 500000:\n",
    "            tokenized_text[i] = w2v_model.key_to_index[tokenized_text[i]]+2\n",
    "        else:\n",
    "            tokenized_text[i] = 1\n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500002, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3467/3467 [00:00<00:00, 10829.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(tokenized_texts)), total=len(tokenized_texts)):\n",
    "    tokenized_texts[i] = preprocess_toks(tokenized_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "tokenized_texts = pad_sequences(\n",
    "    tokenized_texts, maxlen=MAX_LEN, dtype='int32', padding='post',\n",
    "    truncating='post', value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, GRU, Embedding, LSTM\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indexes = Input((50,), dtype='int32')\n",
    "\n",
    "word_emb = Embedding(500002, 300, weights=[emb_matrix], \n",
    "                     trainable=False, mask_zero=True)\n",
    "\n",
    "emb_sequence = word_emb(word_indexes) # (22, 300)\n",
    "rnn1 = GRU(50, activation='tanh')(emb_sequence) # (1,50)\n",
    "dense1 = Dense(50, activation='tanh')(rnn1)\n",
    "dense2 = Dense(50, activation='tanh')(dense1)\n",
    "dense3 = Dense(50, activation='tanh')(dense2)\n",
    "\n",
    "out = Dense(1, activation=None)(dense3)\n",
    "model = Model(inputs=word_indexes, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=opt, loss=\"mse\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14/14 [==============================] - 8s 114ms/step - loss: 0.2437 - mae: 0.3995\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.1970 - mae: 0.3664\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.1878 - mae: 0.3688\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.1841 - mae: 0.3659\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.1822 - mae: 0.3666\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.1812 - mae: 0.3634\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 0.1800 - mae: 0.3579\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.1804 - mae: 0.3681\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.1753 - mae: 0.3526\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.1727 - mae: 0.3521\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.1746 - mae: 0.3452\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.1701 - mae: 0.3514\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.1671 - mae: 0.3402\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.1634 - mae: 0.3372\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.1626 - mae: 0.3347\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.1598 - mae: 0.3360\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.1549 - mae: 0.3276\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.1529 - mae: 0.3192\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.1486 - mae: 0.3184\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.1527 - mae: 0.3186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24892703a60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tokenized_texts, train['sarcastic'].values, epochs=20, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298     damn, imagine being vaxxed and then getting a ...\n",
       "1691    that second vaccine dose is no joke is it 😵 be...\n",
       "1407    my essay was so bad that my prof is giving me ...\n",
       "1888    @iamgryphoneer i don't like to rag on people's...\n",
       "1047    my stray boy playing… he is looking well but s...\n",
       "                              ...                        \n",
       "2275    damn instagram engagement is slow 😭 2 likes in...\n",
       "1006    i gotta get out of this city. i made $18 doord...\n",
       "1563    my grandpa has covid so i made a lil care pack...\n",
       "2630    the last football game i went too. 1 year toda...\n",
       "1615         words cannot express how much i hate glitter\n",
       "Name: tweet, Length: 694, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 694/694 [00:00<00:00, 3652.78it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts_test = []\n",
    "for texto in tqdm(X_test):\n",
    "    tokenized_texts_test.append(nltk.word_tokenize(texto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 694/694 [00:00<00:00, 3691.68it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(tokenized_texts_test)), total=len(tokenized_texts_test)):\n",
    "    tokenized_texts_test[i] = preprocess_toks(tokenized_texts_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts_test = pad_sequences(\n",
    "    tokenized_texts_test, maxlen=MAX_LEN, dtype='int32', padding='post',\n",
    "    truncating='post', value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(tokenized_texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (preds >= 0.5).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       532\n",
      "           1       0.92      0.93      0.93       162\n",
      "\n",
      "    accuracy                           0.97       694\n",
      "   macro avg       0.95      0.95      0.95       694\n",
      "weighted avg       0.97      0.97      0.97       694\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9476062842290913"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "print(classification_report(y_test, y_pred))\n",
    "roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creo una nueva red con LSTM y un EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indexes = Input((50,), dtype='int32')\n",
    "\n",
    "word_emb = Embedding(500002, 300, weights=[emb_matrix], \n",
    "                     trainable=False, mask_zero=True)\n",
    "\n",
    "emb_sequence = word_emb(word_indexes) \n",
    "rnn1 = LSTM(50, activation='tanh')(emb_sequence)\n",
    "dense1 = Dense(50, activation='tanh')(rnn1)\n",
    "dense2 = Dense(50, activation='tanh')(dense1)\n",
    "dense3 = Dense(50, activation='tanh')(dense2)\n",
    "\n",
    "out = Dense(1, activation='sigmoid')(dense3)\n",
    "model = Model(inputs=word_indexes, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer=opt, loss='mse', metrics=[keras.metrics.AUC()])\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 8s 276ms/step - loss: 0.0250 - auc_18: 0.9556 - val_loss: 0.1799 - val_auc_18: 0.0000e+00\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 2s 142ms/step - loss: 0.0247 - auc_18: 0.9565 - val_loss: 0.1865 - val_auc_18: 0.0000e+00\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 2s 138ms/step - loss: 0.0248 - auc_18: 0.9561 - val_loss: 0.1832 - val_auc_18: 0.0000e+00\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.0248 - auc_18: 0.9573 - val_loss: 0.1753 - val_auc_18: 0.0000e+00\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 2s 129ms/step - loss: 0.0249 - auc_18: 0.9565 - val_loss: 0.1883 - val_auc_18: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(tokenized_texts, train['sarcastic'].values, validation_split=0.1, callbacks=[callback], epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(history.history['loss']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(tokenized_texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (preds >= 0.5).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       532\n",
      "           1       0.92      0.93      0.93       162\n",
      "\n",
      "    accuracy                           0.97       694\n",
      "   macro avg       0.95      0.95      0.95       694\n",
      "weighted avg       0.97      0.97      0.97       694\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.946799870045484"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
